{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84456438",
   "metadata": {},
   "source": [
    "## Data Analysis and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720444f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b45d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = pd.read_csv('data/title.basics.tsv', sep='\\t')\n",
    "all_ratings = pd.read_csv('data/title.ratings.tsv', sep='\\t')\n",
    "\n",
    "# Filter titles to only include movies and TV series\n",
    "movies_and_series = all_titles[all_titles['titleType'].isin(['movie', 'tvSeries'])]\n",
    "\n",
    "# Convert columns to correct data types\n",
    "all_ratings['averageRating'] = pd.to_numeric(all_ratings['averageRating'], errors='coerce')\n",
    "all_ratings['numVotes'] = pd.to_numeric(all_ratings['numVotes'], errors='coerce')\n",
    "\n",
    "# Merge titles and ratings, keeping only movies and TV series\n",
    "merged_data = movies_and_series.merge(all_ratings, on='tconst', how='inner')\n",
    "\n",
    "# Filter movies/series with at least 1000 votes\n",
    "df_filtered = merged_data[merged_data['numVotes'] >= 1000]\n",
    "\n",
    "# Sort by rating (descending), then by numVotes (descending for tie-breaking)\n",
    "df_sorted = df_filtered.sort_values(by=['averageRating', 'numVotes'], ascending=[False, False])\n",
    "\n",
    "# Save to new TSV file\n",
    "df_sorted.to_csv('data/filtered_sorted_with_ratings.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be4d72aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean rating: 6.39\n",
      "Minimum votes threshold (75th percentile): 10202\n",
      "\n",
      "Top 10 movies/series by weighted rating:\n",
      "                      primaryTitle  averageRating  numVotes  weightedRating\n",
      "175388                Breaking Bad            9.5   2405005        9.486874\n",
      "67193     The Shawshank Redemption            9.3   3104334        9.290476\n",
      "153336  Avatar: The Last Airbender            9.3    417720        9.230683\n",
      "129412                    The Wire            9.3    413512        9.229994\n",
      "176712             Game of Thrones            9.2   2485498        9.188523\n",
      "39197                The Godfather            9.2   2163561        9.186824\n",
      "80066                 The Sopranos            9.2    545115        9.148422\n",
      "162488             The Dark Knight            9.1   3079402        9.091060\n",
      "308327             Attack on Titan            9.1    649760        9.058146\n",
      "234194                   Aspirants            9.1    316623        9.015484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_10268\\175845366.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['weightedRating'] = df_filtered.apply(calculate_weighted_rating, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# IMDb-style weighted rating system for top 10,000 movies and series\n",
    "\n",
    "# Calculate overall statistics for the weighted rating formula\n",
    "overall_mean_rating = df_filtered['averageRating'].mean()\n",
    "min_votes_required = df_filtered['numVotes'].quantile(0.75)  # Use 75th percentile as minimum\n",
    "\n",
    "print(f\"Overall mean rating: {overall_mean_rating:.2f}\")\n",
    "print(f\"Minimum votes threshold (75th percentile): {min_votes_required:.0f}\")\n",
    "\n",
    "# Apply Bayesian weighted rating formula\n",
    "# Weighted Rating = (v / (v + m)) * R + (m / (v + m)) * C\n",
    "# Where: v = votes, m = min votes, R = average rating, C = overall mean\n",
    "def calculate_weighted_rating(row):\n",
    "    v = row['numVotes']\n",
    "    R = row['averageRating']\n",
    "    m = min_votes_required\n",
    "    C = overall_mean_rating\n",
    "    \n",
    "    weighted_rating = (v / (v + m)) * R + (m / (v + m)) * C\n",
    "    return weighted_rating\n",
    "\n",
    "# Add weighted rating column\n",
    "df_filtered['weightedRating'] = df_filtered.apply(calculate_weighted_rating, axis=1)\n",
    "\n",
    "# Sort by weighted rating (descending), then by numVotes (descending for tie-breaking)\n",
    "df_weighted_sorted = df_filtered.sort_values(by=['weightedRating', 'numVotes'], ascending=[False, False])\n",
    "\n",
    "# Get top 10,000 based on weighted ratings\n",
    "top_10000_weighted = df_weighted_sorted.head(10000)\n",
    "\n",
    "# Save the weighted top 10,000 to file\n",
    "top_10000_weighted.to_csv('data/top_10000_weighted_ratings.tsv', sep='\\t', index=False)\n",
    "\n",
    "print(f\"\\nTop 10 movies/series by weighted rating:\")\n",
    "print(top_10000_weighted[['primaryTitle', 'averageRating', 'numVotes', 'weightedRating']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76639737",
   "metadata": {},
   "source": [
    "## Adding Cast to data we already have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e22374",
   "metadata": {},
   "source": [
    "### Clean title.principals.tsv to only have movies/series in top 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d23cbf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean title.principals.tsv to only have movies/series in top 10000\n",
    "all_principals = pd.read_csv('data/title.principals.tsv', sep='\\t')\n",
    "top_10000_df = pd.read_csv('data/top_10000_weighted_ratings.tsv', sep='\\t')\n",
    "\n",
    "# Filter all_principals to only include titles in top_10000_df\n",
    "filtered_principals = all_principals[all_principals['tconst'].isin(top_10000_df['tconst'])]\n",
    "filtered_principals.to_csv('data/filtered_title_principals_top_10000.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5046652",
   "metadata": {},
   "source": [
    "### Getting top 3 actor/actress names and their respective characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc49e993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10000 entries in chunks of 500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing chunk 1: entries 1 to 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1:  10%|█         | 51/500 [01:25<12:46,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1:  20%|██        | 101/500 [02:48<11:20,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1:  30%|███       | 151/500 [04:12<09:53,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1:  40%|████      | 201/500 [05:44<08:54,  1.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1:  50%|█████     | 251/500 [07:10<07:12,  1.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1:  60%|██████    | 301/500 [08:33<05:48,  1.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1:  70%|███████   | 351/500 [10:02<04:40,  1.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 1: 100%|██████████| 500/500 [14:12<00:00,  1.70s/it]\u001b[A\n",
      "Chunk 1: 100%|██████████| 500/500 [14:12<00:00,  1.70s/it]52.11s/it]\n",
      "Processing chunks:   5%|▌         | 1/20 [14:12<4:29:50, 852.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_001_00001_to_00500.tsv\n",
      "  Chunk 1 completed successfully!\n",
      "\n",
      "Processing chunk 2: entries 501 to 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 2:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 2:  20%|██        | 101/500 [02:54<09:30,  1.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 2:  30%|███       | 151/500 [04:15<10:07,  1.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 2:  50%|█████     | 251/500 [07:05<06:15,  1.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 2:  60%|██████    | 301/500 [08:26<04:37,  1.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 2:  70%|███████   | 351/500 [09:49<03:21,  1.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 2:  80%|████████  | 401/500 [11:10<02:12,  1.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 2: 100%|██████████| 500/500 [13:50<00:00,  1.66s/it]\u001b[A\n",
      "Processing chunks:  10%|█         | 2/20 [28:02<4:11:50, 839.49s/it]\n",
      "Processing chunks:  10%|█         | 2/20 [28:02<4:11:50, 839.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_002_00501_to_01000.tsv\n",
      "  Chunk 2 completed successfully!\n",
      "\n",
      "Processing chunk 3: entries 1001 to 1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 3:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 3:  10%|█         | 51/500 [01:24<12:46,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 3:  20%|██        | 101/500 [02:50<11:16,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 3:  30%|███       | 151/500 [04:15<08:07,  1.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 3:  40%|████      | 201/500 [05:40<08:29,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 3:  50%|█████     | 251/500 [07:04<07:04,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 3:  60%|██████    | 301/500 [08:23<05:40,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 3:  70%|███████   | 351/500 [09:44<04:12,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 3:  80%|████████  | 402/500 [11:07<02:09,  1.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 3: 100%|██████████| 500/500 [13:51<00:00,  1.66s/it]\u001b[A\n",
      "Chunk 3: 100%|██████████| 500/500 [13:51<00:00,  1.66s/it]35.81s/it]\n",
      "Processing chunks:  15%|█▌        | 3/20 [41:54<3:56:48, 835.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_003_01001_to_01500.tsv\n",
      "  Chunk 3 completed successfully!\n",
      "\n",
      "Processing chunk 4: entries 1501 to 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 4:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 4:  10%|█         | 51/500 [01:25<12:45,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 4:  20%|██        | 101/500 [02:49<11:12,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 4:  30%|███       | 151/500 [04:10<08:10,  1.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 4:  40%|████      | 201/500 [05:28<07:03,  1.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 4:  50%|█████     | 251/500 [06:50<07:01,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 4:  60%|██████    | 301/500 [08:12<05:36,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 4:  70%|███████   | 351/500 [09:32<04:12,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 4:  80%|████████  | 401/500 [10:54<02:49,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 4: 100%|██████████| 500/500 [13:38<00:00,  1.64s/it]\u001b[A\n",
      "Processing chunks:  20%|██        | 4/20 [55:32<3:41:04, 829.01s/it]\n",
      "Processing chunks:  20%|██        | 4/20 [55:32<3:41:04, 829.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_004_01501_to_02000.tsv\n",
      "  Chunk 4 completed successfully!\n",
      "\n",
      "Processing chunk 5: entries 2001 to 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 5:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 5:  10%|█         | 51/500 [01:24<12:45,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 5:  20%|██        | 101/500 [02:44<10:58,  1.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 5:  30%|███       | 151/500 [04:07<09:43,  1.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 5:  40%|████      | 202/500 [05:24<06:27,  1.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 5:  50%|█████     | 251/500 [06:45<06:10,  1.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 5:  60%|██████    | 301/500 [08:09<05:37,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 5:  70%|███████   | 351/500 [09:23<03:25,  1.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 5:  80%|████████  | 401/500 [10:47<02:47,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 5: 100%|██████████| 500/500 [13:31<00:00,  1.62s/it]\u001b[A\n",
      "Chunk 5: 100%|██████████| 500/500 [13:31<00:00,  1.62s/it] 822.59s/it]\n",
      "Processing chunks:  25%|██▌       | 5/20 [1:09:03<3:25:38, 822.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_005_02001_to_02500.tsv\n",
      "  Chunk 5 completed successfully!\n",
      "\n",
      "Processing chunk 6: entries 2501 to 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 6:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 6:  10%|█         | 51/500 [01:17<12:22,  1.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 6:  20%|██        | 101/500 [02:40<08:39,  1.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 6:  30%|███       | 151/500 [04:05<09:49,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 6:  40%|████      | 201/500 [05:28<08:27,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 6:  50%|█████     | 251/500 [06:49<07:01,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 6:  60%|██████    | 301/500 [08:11<05:34,  1.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 6:  70%|███████   | 351/500 [09:30<04:11,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 6:  80%|████████  | 401/500 [10:52<02:46,  1.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 6: 100%|██████████| 500/500 [13:33<00:00,  1.63s/it]\u001b[A\n",
      "Chunk 6: 100%|██████████| 500/500 [13:33<00:00,  1.63s/it] 819.56s/it]\n",
      "Processing chunks:  30%|███       | 6/20 [1:22:37<3:11:13, 819.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_006_02501_to_03000.tsv\n",
      "  Chunk 6 completed successfully!\n",
      "\n",
      "Processing chunk 7: entries 3001 to 3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 7:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 7:  10%|█         | 51/500 [01:23<10:51,  1.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 7:  20%|██        | 101/500 [02:43<10:28,  1.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 7:  30%|███       | 151/500 [04:01<09:52,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 7:  40%|████      | 201/500 [05:22<08:25,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 7:  50%|█████     | 251/500 [06:45<07:02,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 7:  60%|██████    | 301/500 [08:06<05:35,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 7:  70%|███████   | 351/500 [09:26<04:11,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 7:  80%|████████  | 401/500 [10:50<02:47,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 7: 100%|██████████| 500/500 [13:28<00:00,  1.62s/it]\u001b[A\n",
      "Chunk 7: 100%|██████████| 500/500 [13:28<00:00,  1.62s/it] 815.99s/it]\n",
      "Processing chunks:  35%|███▌      | 7/20 [1:36:06<2:56:47, 815.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_007_03001_to_03500.tsv\n",
      "  Chunk 7 completed successfully!\n",
      "\n",
      "Processing chunk 8: entries 3501 to 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 8:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 8:  10%|█         | 51/500 [01:22<12:30,  1.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 8:  20%|██        | 101/500 [02:39<09:03,  1.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 8:  30%|███       | 151/500 [04:00<09:49,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 8:  50%|█████     | 251/500 [06:26<06:59,  1.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 8:  60%|██████    | 301/500 [07:41<05:20,  1.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 8:  70%|███████   | 351/500 [09:02<04:35,  1.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 8:  80%|████████  | 401/500 [10:24<02:44,  1.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 8: 100%|██████████| 500/500 [13:09<00:00,  1.58s/it]\u001b[A\n",
      "Chunk 8: 100%|██████████| 500/500 [13:09<00:00,  1.58s/it] 807.41s/it]\n",
      "Processing chunks:  40%|████      | 8/20 [1:49:15<2:41:28, 807.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_008_03501_to_04000.tsv\n",
      "  Chunk 8 completed successfully!\n",
      "\n",
      "Processing chunk 9: entries 4001 to 4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 9:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 9:  10%|█         | 51/500 [01:20<12:39,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 9:  20%|██        | 101/500 [02:42<11:18,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 9:  30%|███       | 151/500 [04:05<09:52,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 9:  40%|████      | 201/500 [05:28<08:03,  1.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 9:  50%|█████     | 252/500 [06:41<05:09,  1.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 9:  60%|██████    | 301/500 [07:52<06:19,  1.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 9:  70%|███████   | 351/500 [09:15<04:14,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 9:  80%|████████  | 401/500 [10:36<02:47,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 9: 100%|██████████| 500/500 [13:13<00:00,  1.59s/it]\u001b[A\n",
      "Chunk 9: 100%|██████████| 500/500 [13:13<00:00,  1.59s/it] 803.07s/it]\n",
      "Processing chunks:  45%|████▌     | 9/20 [2:02:28<2:27:13, 803.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_009_04001_to_04500.tsv\n",
      "  Chunk 9 completed successfully!\n",
      "\n",
      "Processing chunk 10: entries 4501 to 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 10:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 10:  10%|█         | 51/500 [01:21<09:45,  1.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 10:  20%|██        | 101/500 [02:42<11:02,  1.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 10:  30%|███       | 151/500 [04:00<07:03,  1.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 10:  40%|████      | 202/500 [05:18<06:16,  1.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 10:  50%|█████     | 251/500 [06:34<05:30,  1.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 10:  60%|██████    | 301/500 [07:54<05:20,  1.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 10:  70%|███████   | 352/500 [09:16<03:11,  1.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 10:  80%|████████  | 401/500 [10:31<02:29,  1.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 10: 100%|██████████| 500/500 [13:12<00:00,  1.59s/it]\u001b[A\n",
      "Chunk 10: 100%|██████████| 500/500 [13:12<00:00,  1.59s/it] 799.93s/it]\n",
      "Processing chunks:  50%|█████     | 10/20 [2:15:41<2:13:19, 799.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_010_04501_to_05000.tsv\n",
      "  Chunk 10 completed successfully!\n",
      "\n",
      "Processing chunk 11: entries 5001 to 5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 11:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 11:  10%|█         | 51/500 [01:18<12:42,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 11:  20%|██        | 101/500 [02:33<09:21,  1.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 11:  30%|███       | 151/500 [03:55<09:38,  1.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 11:  40%|████      | 201/500 [05:08<08:21,  1.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 11:  50%|█████     | 251/500 [06:22<05:42,  1.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 11:  60%|██████    | 301/500 [07:42<05:28,  1.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 11:  70%|███████   | 351/500 [09:01<04:11,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 11:  80%|████████  | 401/500 [10:22<02:47,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 11: 100%|██████████| 500/500 [12:59<00:00,  1.56s/it]\u001b[A\n",
      "Chunk 11: 100%|██████████| 500/500 [12:59<00:00,  1.56s/it] 793.60s/it]\n",
      "Processing chunks:  55%|█████▌    | 11/20 [2:28:41<1:59:02, 793.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_011_05001_to_05500.tsv\n",
      "  Chunk 11 completed successfully!\n",
      "\n",
      "Processing chunk 12: entries 5501 to 6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 12:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 12:  10%|█         | 51/500 [01:23<12:34,  1.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 12:  20%|██        | 102/500 [02:43<08:35,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 12:  30%|███       | 151/500 [04:02<09:51,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 12:  40%|████      | 201/500 [05:23<08:29,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 12:  50%|█████     | 251/500 [06:39<06:52,  1.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 12:  60%|██████    | 301/500 [07:58<05:37,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 12:  70%|███████   | 351/500 [09:15<04:08,  1.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 12:  80%|████████  | 401/500 [10:32<02:19,  1.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 12: 100%|██████████| 500/500 [13:13<00:00,  1.59s/it]\u001b[A\n",
      "Chunk 12: 100%|██████████| 500/500 [13:13<00:00,  1.59s/it] 793.54s/it]\n",
      "Processing chunks:  60%|██████    | 12/20 [2:41:54<1:45:48, 793.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_012_05501_to_06000.tsv\n",
      "  Chunk 12 completed successfully!\n",
      "\n",
      "Processing chunk 13: entries 6001 to 6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 13:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 13:  10%|█         | 51/500 [01:21<12:49,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 13:  20%|██        | 101/500 [02:43<11:17,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 13:  30%|███       | 151/500 [04:05<09:55,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 13:  40%|████      | 202/500 [05:21<04:41,  1.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 13:  50%|█████     | 251/500 [06:42<07:04,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 13:  60%|██████    | 301/500 [08:05<04:40,  1.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 13:  70%|███████   | 351/500 [09:26<03:27,  1.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 13:  80%|████████  | 401/500 [10:37<01:21,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 13: 100%|██████████| 500/500 [13:04<00:00,  1.57s/it]\u001b[A\n",
      "Chunk 13: 100%|██████████| 500/500 [13:04<00:00,  1.57s/it] 790.71s/it]\n",
      "Processing chunks:  65%|██████▌   | 13/20 [2:54:58<1:32:14, 790.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_013_06001_to_06500.tsv\n",
      "  Chunk 13 completed successfully!\n",
      "\n",
      "Processing chunk 14: entries 6501 to 7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 14:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 14:  10%|█         | 51/500 [01:18<10:35,  1.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 14:  20%|██        | 101/500 [02:35<11:16,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 14:  30%|███       | 151/500 [03:57<09:59,  1.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 14:  40%|████      | 201/500 [05:16<08:32,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 14:  50%|█████     | 252/500 [06:38<05:26,  1.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 14:  60%|██████    | 301/500 [07:54<05:27,  1.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 14:  70%|███████   | 352/500 [09:16<02:54,  1.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 14:  80%|████████  | 401/500 [10:35<02:32,  1.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 14: 100%|██████████| 500/500 [13:02<00:00,  1.57s/it]\u001b[A\n",
      "Processing chunks:  70%|███████   | 14/20 [3:08:01<1:18:49, 788.30s/it]\n",
      "Processing chunks:  70%|███████   | 14/20 [3:08:01<1:18:49, 788.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_014_06501_to_07000.tsv\n",
      "  Chunk 14 completed successfully!\n",
      "\n",
      "Processing chunk 15: entries 7001 to 7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 15:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 15:  10%|█         | 51/500 [01:16<09:36,  1.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 15:  20%|██        | 101/500 [02:39<11:19,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 15:  30%|███       | 151/500 [04:02<09:53,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 15:  40%|████      | 201/500 [05:20<06:15,  1.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 15:  50%|█████     | 251/500 [06:45<07:04,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 15:  60%|██████    | 301/500 [08:05<05:06,  1.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 15:  70%|███████   | 351/500 [09:24<04:07,  1.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 15:  80%|████████  | 401/500 [10:47<02:48,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 15: 100%|██████████| 500/500 [13:14<00:00,  1.59s/it]\u001b[A\n",
      "Chunk 15: 100%|██████████| 500/500 [13:14<00:00,  1.59s/it] 790.17s/it]\n",
      "Processing chunks:  75%|███████▌  | 15/20 [3:21:15<1:05:50, 790.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_015_07001_to_07500.tsv\n",
      "  Chunk 15 completed successfully!\n",
      "\n",
      "Processing chunk 16: entries 7501 to 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 16:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 16:  10%|█         | 51/500 [01:21<11:08,  1.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 16:  20%|██        | 101/500 [02:40<11:12,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 16:  30%|███       | 151/500 [03:58<07:44,  1.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 16:  40%|████      | 201/500 [05:16<05:18,  1.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 16:  50%|█████     | 251/500 [06:36<07:00,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 16:  60%|██████    | 301/500 [07:50<03:50,  1.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 16:  70%|███████   | 351/500 [09:13<04:15,  1.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 16:  80%|████████  | 401/500 [10:33<02:13,  1.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 16: 100%|██████████| 500/500 [13:06<00:00,  1.57s/it]\u001b[A\n",
      "Processing chunks:  80%|████████  | 16/20 [3:34:22<52:35, 788.97s/it]  \n",
      "Processing chunks:  80%|████████  | 16/20 [3:34:22<52:35, 788.97s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_016_07501_to_08000.tsv\n",
      "  Chunk 16 completed successfully!\n",
      "\n",
      "Processing chunk 17: entries 8001 to 8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 17:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 17:  10%|█         | 51/500 [01:17<12:28,  1.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 17:  20%|██        | 101/500 [02:40<11:21,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 17:  30%|███       | 151/500 [04:00<09:50,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 17:  40%|████      | 201/500 [05:23<07:53,  1.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 17:  50%|█████     | 251/500 [06:39<07:01,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 17:  60%|██████    | 302/500 [08:01<03:53,  1.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 17:  70%|███████   | 351/500 [09:15<03:30,  1.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 17:  80%|████████  | 401/500 [10:33<01:57,  1.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 17: 100%|██████████| 500/500 [13:09<00:00,  1.58s/it]\u001b[A\n",
      "Chunk 17: 100%|██████████| 500/500 [13:09<00:00,  1.58s/it]89.28s/it]\n",
      "Processing chunks:  85%|████████▌ | 17/20 [3:47:32<39:27, 789.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_017_08001_to_08500.tsv\n",
      "  Chunk 17 completed successfully!\n",
      "\n",
      "Processing chunk 18: entries 8501 to 9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 18:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 18:  10%|█         | 51/500 [01:41<12:48,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 18:  20%|██        | 101/500 [03:02<10:16,  1.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 18:  30%|███       | 151/500 [04:18<08:17,  1.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 18:  40%|████      | 201/500 [05:37<08:31,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 18:  50%|█████     | 251/500 [06:55<07:05,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 18:  60%|██████    | 301/500 [08:11<05:41,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 18:  70%|███████   | 351/500 [09:32<03:50,  1.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 18:  80%|████████  | 401/500 [10:48<02:20,  1.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 18: 100%|██████████| 500/500 [13:19<00:00,  1.60s/it]\u001b[A\n",
      "Processing chunks:  90%|█████████ | 18/20 [4:00:51<26:24, 792.33s/it]\n",
      "Processing chunks:  90%|█████████ | 18/20 [4:00:51<26:24, 792.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_018_08501_to_09000.tsv\n",
      "  Chunk 18 completed successfully!\n",
      "\n",
      "Processing chunk 19: entries 9001 to 9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 19:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 19:  10%|█         | 51/500 [01:20<11:11,  1.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 19:  20%|██        | 101/500 [02:39<08:49,  1.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 19:  30%|███       | 151/500 [03:53<07:31,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 19:  40%|████      | 201/500 [05:13<06:34,  1.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 19:  51%|█████     | 253/500 [06:32<03:49,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 19:  60%|██████    | 302/500 [07:48<03:55,  1.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 19:  70%|███████   | 351/500 [09:05<04:18,  1.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 19:  80%|████████  | 401/500 [10:24<02:38,  1.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 19: 100%|██████████| 500/500 [12:53<00:00,  1.55s/it]\u001b[A\n",
      "Chunk 19: 100%|██████████| 500/500 [12:53<00:00,  1.55s/it]86.81s/it]\n",
      "Processing chunks:  95%|█████████▌| 19/20 [4:13:45<13:06, 786.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_019_09001_to_09500.tsv\n",
      "  Chunk 19 completed successfully!\n",
      "\n",
      "Processing chunk 20: entries 9501 to 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 20:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 50/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 20:  10%|█         | 51/500 [01:25<12:28,  1.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 100/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 20:  20%|██        | 101/500 [02:41<08:45,  1.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 150/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 20:  30%|███       | 151/500 [03:57<09:24,  1.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 200/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 20:  40%|████      | 201/500 [05:18<08:27,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 250/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 20:  50%|█████     | 251/500 [06:41<06:36,  1.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 300/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 350/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 20:  70%|███████   | 351/500 [09:12<04:04,  1.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 400/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 20:  80%|████████  | 401/500 [10:25<02:47,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 450/500 in current chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk 20: 100%|██████████| 500/500 [12:58<00:00,  1.56s/it]\u001b[A\n",
      "Chunk 20: 100%|██████████| 500/500 [12:58<00:00,  1.56s/it]00.19s/it]\n",
      "Processing chunks: 100%|██████████| 20/20 [4:26:43<00:00, 800.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/500 in current chunk\n",
      "  Saved chunk to: data/cast_data/chunks/chunk_020_09501_to_10000.tsv\n",
      "  Chunk 20 completed successfully!\n",
      "\n",
      "Combining all chunks...\n",
      "\n",
      "Processing completed! Final results saved to 'data/cast_data/top_10_with_cast.tsv'\n",
      "Total entries processed: 10000\n",
      "\n",
      "Sample results:\n",
      "                 primaryTitle  \\\n",
      "0                Breaking Bad   \n",
      "1    The Shawshank Redemption   \n",
      "2  Avatar: The Last Airbender   \n",
      "3                    The Wire   \n",
      "4             Game of Thrones   \n",
      "5               The Godfather   \n",
      "6                The Sopranos   \n",
      "7             The Dark Knight   \n",
      "8             Attack on Titan   \n",
      "9                   Aspirants   \n",
      "\n",
      "                                          top_3_cast  \n",
      "0  [(Bryan Cranston, Walter White), (Aaron Paul, ...  \n",
      "1  [(Tim Robbins, Andy Dufresne), (Morgan Freeman...  \n",
      "2  [(Dee Bradley Baker, Appa), (Zach Tyler Eisen,...  \n",
      "3  [(Dominic West, Detective James 'Jimmy' McNult...  \n",
      "4  [(Emilia Clarke, Daenerys Targaryen), (Peter D...  \n",
      "5  [(Marlon Brando, Don Vito Corleone), (Al Pacin...  \n",
      "6  [(James Gandolfini, Tony Soprano), (Lorraine B...  \n",
      "7  [(Christian Bale, Bruce Wayne), (Heath Ledger,...  \n",
      "8  [(Jessie James Grelle, Armin Arlert), (Bryce P...  \n",
      "9  [(Naveen Kasturia, Abhilash Sharma), (Shivanki...  \n",
      "\n",
      "Chunk files saved in 'data/cast_data/chunks' for backup\n",
      "You can delete the chunks folder once you've verified the final file is correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "principals = pd.read_csv('data/cast_data/filtered_title_principals_top_10000.tsv', sep='\\t')\n",
    "names = pd.read_csv('data/cast_data/name.basics.tsv', sep='\\t')\n",
    "top10000 = pd.read_csv('data/top_10000_weighted_ratings.tsv', sep='\\t')\n",
    "\n",
    "# Sample of top 10 entries for testing - change to top10000 for full processing\n",
    "top10_sample = top10000.head(10)  # Change to top10000 for full dataset\n",
    "\n",
    "# Get each tconst from dataset and find the top 3 UNIQUE actors/actresses nconst in principals and their respective characters\n",
    "def get_top_3_cast(tconst):\n",
    "    cast = principals[principals['tconst'] == tconst]\n",
    "    cast = cast[cast['category'].isin(['actor', 'actress'])]\n",
    "    \n",
    "    result = []\n",
    "    seen_nconst = set()  # Track unique nconst values\n",
    "    \n",
    "    for _, row in cast.iterrows():\n",
    "        nconst = row['nconst']\n",
    "        \n",
    "        # Skip if we've already seen this nconst\n",
    "        if nconst in seen_nconst:\n",
    "            continue\n",
    "            \n",
    "        character = row['characters']\n",
    "        \n",
    "        # Clean the character field - remove brackets and extra quotes\n",
    "        if pd.notna(character) and character != '\\\\N':\n",
    "            import json\n",
    "            try:\n",
    "                # Try to parse as JSON first\n",
    "                character_list = json.loads(character)\n",
    "                if isinstance(character_list, list) and len(character_list) > 0:\n",
    "                    clean_character = character_list[0]  # Get first character name\n",
    "                else:\n",
    "                    clean_character = str(character)\n",
    "            except (json.JSONDecodeError, ValueError):\n",
    "                # If JSON parsing fails, try manual cleaning\n",
    "                clean_character = character.strip('[]\"').replace('\"\"', '\"')\n",
    "        else:\n",
    "            clean_character = \"Unknown Character\"\n",
    "        \n",
    "        name_row = names[names['nconst'] == nconst]\n",
    "        \n",
    "        if not name_row.empty:\n",
    "            actor_name = name_row.iloc[0]['primaryName']\n",
    "            result.append((actor_name, clean_character))\n",
    "            seen_nconst.add(nconst)\n",
    "            \n",
    "            # Stop when we have 3 unique cast members\n",
    "            if len(result) >= 3:\n",
    "                break\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Chunk-based processing with automatic saving\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "chunk_size = 500\n",
    "dataset = top10000  # Change to top10000 for full processing\n",
    "output_dir = 'data/cast_data/chunks'\n",
    "final_output = 'data/cast_data/top_10_with_cast.tsv'  # Change to top_10000_with_cast.tsv for full processing\n",
    "\n",
    "# Create chunks directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Processing {len(dataset)} entries in chunks of {chunk_size}...\")\n",
    "\n",
    "# Process in chunks\n",
    "all_results = []\n",
    "for chunk_start in tqdm(range(0, len(dataset), chunk_size), desc=\"Processing chunks\"):\n",
    "    chunk_end = min(chunk_start + chunk_size, len(dataset))\n",
    "    chunk_data = dataset.iloc[chunk_start:chunk_end].copy()\n",
    "    \n",
    "    print(f\"\\nProcessing chunk {chunk_start//chunk_size + 1}: entries {chunk_start+1} to {chunk_end}\")\n",
    "    \n",
    "    # Process each entry in the chunk\n",
    "    chunk_results = []\n",
    "    for idx, (_, row) in enumerate(tqdm(chunk_data.iterrows(), total=len(chunk_data), desc=f\"Chunk {chunk_start//chunk_size + 1}\")):\n",
    "        try:\n",
    "            cast_result = get_top_3_cast(row['tconst'])\n",
    "            chunk_results.append(cast_result)\n",
    "            \n",
    "            # Print progress every 50 entries within chunk\n",
    "            if (idx + 1) % 50 == 0:\n",
    "                print(f\"  Processed {idx + 1}/{len(chunk_data)} in current chunk\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {row['tconst']}: {e}\")\n",
    "            chunk_results.append([])  # Empty result for failed entries\n",
    "    \n",
    "    # Add results to chunk data\n",
    "    chunk_data['top_3_cast'] = chunk_results\n",
    "    \n",
    "    # Save chunk to file\n",
    "    chunk_filename = f\"{output_dir}/chunk_{chunk_start//chunk_size + 1:03d}_{chunk_start+1:05d}_to_{chunk_end:05d}.tsv\"\n",
    "    chunk_data.to_csv(chunk_filename, sep='\\t', index=False)\n",
    "    print(f\"  Saved chunk to: {chunk_filename}\")\n",
    "    \n",
    "    # Add to all results\n",
    "    all_results.append(chunk_data)\n",
    "    \n",
    "    print(f\"  Chunk {chunk_start//chunk_size + 1} completed successfully!\")\n",
    "\n",
    "# Combine all chunks\n",
    "print(\"\\nCombining all chunks...\")\n",
    "final_dataset = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Save final combined result\n",
    "final_dataset.to_csv(final_output, sep='\\t', index=False)\n",
    "print(f\"\\nProcessing completed! Final results saved to '{final_output}'\")\n",
    "print(f\"Total entries processed: {len(final_dataset)}\")\n",
    "\n",
    "# Display sample results\n",
    "print(\"\\nSample results:\")\n",
    "print(final_dataset[['primaryTitle', 'top_3_cast']].head(10))\n",
    "\n",
    "# Clean up chunk files (optional - comment out if you want to keep them)\n",
    "print(f\"\\nChunk files saved in '{output_dir}' for backup\")\n",
    "print(\"You can delete the chunks folder once you've verified the final file is correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b35eb5f",
   "metadata": {},
   "source": [
    "## Web Scraping for Movie/Series Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b4f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\franc\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\franc\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\franc\\AppData\\Roaming\\Python\\Python311\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\franc\\miniconda3\\envs\\envacfinal\\lib\\site-packages (4.14.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\franc\\miniconda3\\envs\\envacfinal\\lib\\site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\franc\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4) (4.13.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Starting web scraping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping: Breaking Bad (2008) - https://www.streamwithvpn.com/breaking-bad-2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:   2%|▏         | 1/50 [00:01<01:24,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/breaking-bad-2008\n",
      "✓ Found description for Breaking Bad: Walter White, a New Mexico chemistry teacher, is diagnosed with Stage III cancer and given a prognos...\n",
      "\n",
      "Scraping: The Shawshank Redemption (1994) - https://www.streamwithvpn.com/the-shawshank-redemption-1994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:   4%|▍         | 2/50 [00:03<01:21,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/the-shawshank-redemption-1994\n",
      "✓ Found description for The Shawshank Redemption: Imprisoned in the 1940s for the double murder of his wife and her lover, upstanding banker Andy Dufr...\n",
      "\n",
      "Scraping: Avatar: The Last Airbender (2005) - https://www.streamwithvpn.com/avatar-the-last-airbender-2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:   6%|▌         | 3/50 [00:05<01:20,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/avatar-the-last-airbender-2005\n",
      "✓ Found description for Avatar: The Last Airbender: In a war-torn world of elemental magic, a young boy reawakens to undertake a dangerous mystic quest ...\n",
      "\n",
      "Scraping: The Wire (2002) - https://www.streamwithvpn.com/the-wire-2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:   8%|▊         | 4/50 [00:06<01:19,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/the-wire-2002\n",
      "✓ Found description for The Wire: Told from the points of view of both the Baltimore homicide and narcotics detectives and their targe...\n",
      "\n",
      "Scraping: Game of Thrones (2011) - https://www.streamwithvpn.com/game-of-thrones-2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  10%|█         | 5/50 [00:08<01:20,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/game-of-thrones-2011\n",
      "✓ Found description for Game of Thrones: Seven noble families fight for control of the mythical land of Westeros. Friction between the houses...\n",
      "\n",
      "Scraping: The Godfather (1972) - https://www.streamwithvpn.com/the-godfather-1972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  12%|█▏        | 6/50 [00:10<01:17,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/the-godfather-1972\n",
      "✓ Found description for The Godfather: Spanning the years 1945 to 1955, a chronicle of the fictional Italian-American Corleone crime family...\n",
      "\n",
      "Scraping: The Sopranos (1999) - https://www.streamwithvpn.com/the-sopranos-1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  14%|█▍        | 7/50 [00:12<01:20,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/the-sopranos-1999\n",
      "✓ Found description for The Sopranos: The story of New Jersey-based Italian-American mobster Tony Soprano and the difficulties he faces as...\n",
      "\n",
      "Scraping: The Dark Knight (2008) - https://www.streamwithvpn.com/the-dark-knight-2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  16%|█▌        | 8/50 [00:14<01:16,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/the-dark-knight-2008\n",
      "✓ Found description for The Dark Knight: Batman raises the stakes in his war on crime. With the help of Lt. Jim Gordon and District Attorney ...\n",
      "\n",
      "Scraping: Attack on Titan (2013) - https://www.streamwithvpn.com/attack-on-titan-2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  18%|█▊        | 9/50 [00:16<01:16,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/attack-on-titan-2013\n",
      "✓ Found description for Attack on Titan: 100 years ago, the last remnants of humanity were forced to retreat behind the towering walls of a f...\n",
      "\n",
      "Scraping: Aspirants (2021) - https://www.streamwithvpn.com/aspirants-2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  20%|██        | 10/50 [00:18<01:12,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/aspirants-2021\n",
      "✓ Found description for Aspirants: Aspirants is a story of 3 friends - Abhilash, SK, and Guri. The story takes place in the past and th...\n",
      "\n",
      "Scraping: The Lord of the Rings: The Return of the King (2003) - https://www.streamwithvpn.com/the-lord-of-the-rings-the-return-of-the-king-2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  22%|██▏       | 11/50 [00:19<01:09,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/the-lord-of-the-rings-the-return-of-the-king-2003\n",
      "✓ Found description for The Lord of the Rings: The Return of the King: As armies mass for a final battle that will decide the fate of the world--and powerful, ancient forc...\n",
      "\n",
      "Scraping: Fullmetal Alchemist: Brotherhood (2009) - https://www.streamwithvpn.com/fullmetal-alchemist-brotherhood-2009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  24%|██▍       | 12/50 [00:21<01:09,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/fullmetal-alchemist-brotherhood-2009\n",
      "✓ Found description for Fullmetal Alchemist: Brotherhood: Disregard for alchemy’s laws ripped half of Edward Elric’s limbs from his body and left his brother ...\n",
      "\n",
      "Scraping: Schindler's List (1993) - https://www.streamwithvpn.com/schindlers-list-1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  26%|██▌       | 13/50 [00:23<01:06,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/schindlers-list-1993\n",
      "✓ Found description for Schindler's List: The true story of how businessman Oskar Schindler saved over a thousand Jewish lives from the Nazis ...\n",
      "\n",
      "Scraping: The Godfather Part II (1974) - https://www.streamwithvpn.com/the-godfather-part-ii-1974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  28%|██▊       | 14/50 [00:25<01:03,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/the-godfather-part-ii-1974\n",
      "✓ Found description for The Godfather Part II: In the continuing saga of the Corleone crime family, a young Vito Corleone grows up in Sicily and in...\n",
      "\n",
      "Scraping: Sherlock (2010) - https://www.streamwithvpn.com/sherlock-2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  30%|███       | 15/50 [00:26<01:01,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/sherlock-2010\n",
      "✓ Found description for Sherlock: A modern update finds the famous sleuth and his doctor partner solving crime in 21st century London....\n",
      "\n",
      "Scraping: 12 Angry Men (1957) - https://www.streamwithvpn.com/12-angry-men-1957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  32%|███▏      | 16/50 [00:28<00:58,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/12-angry-men-1957\n",
      "✓ Found description for 12 Angry Men: The defense and the prosecution have rested and the jury is filing into the jury room to decide if a...\n",
      "\n",
      "Scraping: The Office (2005) - https://www.streamwithvpn.com/the-office-2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  34%|███▍      | 17/50 [00:30<00:58,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/the-office-2005\n",
      "✓ Found description for The Office: The everyday lives of office employees in the Scranton, Pennsylvania branch of the fictional Dunder ...\n",
      "\n",
      "Scraping: Better Call Saul (2015) - https://www.streamwithvpn.com/better-call-saul-2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  36%|███▌      | 18/50 [00:32<00:56,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/better-call-saul-2015\n",
      "✓ Found description for Better Call Saul: Six years before Saul Goodman meets Walter White. We meet him when the man who will become Saul Good...\n",
      "\n",
      "Scraping: Rick and Morty (2013) - https://www.streamwithvpn.com/rick-and-morty-2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  38%|███▊      | 19/50 [00:33<00:55,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/rick-and-morty-2013\n",
      "✓ Found description for Rick and Morty: Rick is a mentally-unbalanced but scientifically gifted old man who has recently reconnected with hi...\n",
      "\n",
      "Scraping: Arcane (2021) - https://www.streamwithvpn.com/arcane-2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  40%|████      | 20/50 [00:35<00:52,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/arcane-2021\n",
      "✓ Found description for Arcane: Amid the stark discord of twin cities Piltover and Zaun, two sisters fight on rival sides of a war b...\n",
      "\n",
      "Scraping: One Piece (1999) - https://www.streamwithvpn.com/one-piece-1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  42%|████▏     | 21/50 [00:37<00:51,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/one-piece-1999\n",
      "✓ Found description for One Piece: Years ago, the fearsome Pirate King, Gol D. Roger was executed leaving a huge pile of treasure and t...\n",
      "\n",
      "Scraping: The Lord of the Rings: The Fellowship of the Ring (2001) - https://www.streamwithvpn.com/the-lord-of-the-rings-the-fellowship-of-the-ring-2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  44%|████▍     | 22/50 [00:39<00:49,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/the-lord-of-the-rings-the-fellowship-of-the-ring-2001\n",
      "✓ Found description for The Lord of the Rings: The Fellowship of the Ring: Young hobbit Frodo Baggins, after inheriting a mysterious ring from his uncle Bilbo, must leave his ...\n",
      "\n",
      "Scraping: Friends (1994) - https://www.streamwithvpn.com/friends-1994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  46%|████▌     | 23/50 [00:40<00:48,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/friends-1994\n",
      "✓ Found description for Friends: Six young people from New York City, on their own and struggling to survive in the real world, find ...\n",
      "\n",
      "Scraping: True Detective (2014) - https://www.streamwithvpn.com/true-detective-2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  48%|████▊     | 24/50 [00:42<00:45,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/true-detective-2014\n",
      "✓ Found description for True Detective: An American anthology police detective series utilizing multiple timelines in which investigations s...\n",
      "\n",
      "Scraping: Sapne Vs Everyone (2023) - https://www.streamwithvpn.com/sapne-vs-everyone-2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  50%|█████     | 25/50 [00:44<00:42,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/sapne-vs-everyone-2023\n",
      "✓ Found description for Sapne Vs Everyone: Two obsessive dreamers collide with the resistance of expectations, morality and each other....\n",
      "\n",
      "Scraping: Hunter x Hunter (2011) - https://www.streamwithvpn.com/hunter-x-hunter-2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  52%|█████▏    | 26/50 [00:46<00:41,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/hunter-x-hunter-2011\n",
      "✓ Found description for Hunter x Hunter: To fulfill his dreams of becoming a legendary Hunter like his dad, a young boy must pass a rigorous ...\n",
      "\n",
      "Scraping: Death Note (2006) - https://www.streamwithvpn.com/death-note-2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  54%|█████▍    | 27/50 [00:47<00:39,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/death-note-2006\n",
      "✓ Found description for Death Note: Light Yagami is an ace student with great prospects—and he’s bored out of his mind. But all that cha...\n",
      "\n",
      "Scraping: Dexter: Resurrection (2025) - https://www.streamwithvpn.com/dexter-resurrection-2025\n",
      "⚠ Original URL failed (404), trying without year: https://www.streamwithvpn.com/dexter-resurrection\n",
      "⚠ Original URL failed (404), trying without year: https://www.streamwithvpn.com/dexter-resurrection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  56%|█████▌    | 28/50 [00:49<00:39,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with URL without year: https://www.streamwithvpn.com/dexter-resurrection\n",
      "✓ Found description for Dexter: Resurrection: Dexter Morgan awakens from a coma to find Harrison gone without a trace. Realizing the weight of wha...\n",
      "\n",
      "Scraping: Seinfeld (1989) - https://www.streamwithvpn.com/seinfeld-1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  58%|█████▊    | 29/50 [00:51<00:38,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/seinfeld-1989\n",
      "✓ Found description for Seinfeld: A stand-up comedian and his three offbeat friends weather the pitfalls and payoffs of life in New Yo...\n",
      "\n",
      "Scraping: Firefly (2002) - https://www.streamwithvpn.com/firefly-2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  60%|██████    | 30/50 [00:53<00:36,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/firefly-2002\n",
      "✓ Found description for Firefly: In the year 2517, after the arrival of humans in a new star system, follow the adventures of the ren...\n",
      "\n",
      "Scraping: Batman: The Animated Series (1992) - https://www.streamwithvpn.com/batman-the-animated-series-1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  62%|██████▏   | 31/50 [00:55<00:33,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/batman-the-animated-series-1992\n",
      "✓ Found description for Batman: The Animated Series: Vowing to avenge the murder of his parents, Bruce Wayne devotes his life to wiping out crime in Goth...\n",
      "\n",
      "Scraping: Inception (2010) - https://www.streamwithvpn.com/inception-2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  64%|██████▍   | 32/50 [00:56<00:32,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/inception-2010\n",
      "✓ Found description for Inception: Cobb, a skilled thief who commits corporate espionage by infiltrating the subconscious of his target...\n",
      "\n",
      "Scraping: Fight Club (1999) - https://www.streamwithvpn.com/fight-club-1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  66%|██████▌   | 33/50 [00:58<00:30,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/fight-club-1999\n",
      "✓ Found description for Fight Club: A ticking-time-bomb insomniac and a slippery soap salesman channel primal male aggression into a sho...\n",
      "\n",
      "Scraping: Forrest Gump (1994) - https://www.streamwithvpn.com/forrest-gump-1994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  68%|██████▊   | 34/50 [01:00<00:28,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/forrest-gump-1994\n",
      "✓ Found description for Forrest Gump: A man with a low IQ has accomplished great things in his life and been present during significant hi...\n",
      "\n",
      "Scraping: Pulp Fiction (1994) - https://www.streamwithvpn.com/pulp-fiction-1994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  70%|███████   | 35/50 [01:02<00:26,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/pulp-fiction-1994\n",
      "✓ Found description for Pulp Fiction: A burger-loving hit man, his philosophical partner, a drug-addled gangster's moll and a washed-up bo...\n",
      "\n",
      "Scraping: The Lord of the Rings: The Two Towers (2002) - https://www.streamwithvpn.com/the-lord-of-the-rings-the-two-towers-2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  72%|███████▏  | 36/50 [01:03<00:24,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/the-lord-of-the-rings-the-two-towers-2002\n",
      "✓ Found description for The Lord of the Rings: The Two Towers: Frodo Baggins and the other members of the Fellowship continue on their sacred quest to destroy the ...\n",
      "\n",
      "Scraping: Our Planet (2019) - https://www.streamwithvpn.com/our-planet-2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  74%|███████▍  | 37/50 [01:05<00:21,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/our-planet-2019\n",
      "✓ Found description for Our Planet: Experience our planet's natural beauty and examine how climate change impacts all living creatures i...\n",
      "\n",
      "Scraping: Sandeep Bhaiya (2023) - https://www.streamwithvpn.com/sandeep-bhaiya-2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  76%|███████▌  | 38/50 [01:06<00:19,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/sandeep-bhaiya-2023\n",
      "✓ Found description for Sandeep Bhaiya: ‘Sandeep Bhaiya’ is a spinoff of the blockbuster webshow TVF Aspirants. It will have a total of eigh...\n",
      "\n",
      "Scraping: TVF Pitchers (2015) - https://www.streamwithvpn.com/tvf-pitchers-2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  78%|███████▊  | 39/50 [01:08<00:17,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/tvf-pitchers-2015\n",
      "✓ Found description for TVF Pitchers: A story of trials and tribulations of four young entrepreneurs who quit their day jobs in order to p...\n",
      "\n",
      "Scraping: Panchayat (2020) - https://www.streamwithvpn.com/panchayat-2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  80%|████████  | 40/50 [01:10<00:16,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/panchayat-2020\n",
      "✓ Found description for Panchayat: Panchayat is a comedy-drama, which captures the journey of an engineering graduate Abhishek, who for...\n",
      "\n",
      "Scraping: The Good, the Bad and the Ugly (1966) - https://www.streamwithvpn.com/the-good-the-bad-and-the-ugly-1966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  82%|████████▏ | 41/50 [01:11<00:14,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/the-good-the-bad-and-the-ugly-1966\n",
      "✓ Found description for The Good, the Bad and the Ugly: While the Civil War rages on between the Union and the Confederacy, three men – a quiet loner, a rut...\n",
      "\n",
      "Scraping: The Twilight Zone (1959) - https://www.streamwithvpn.com/the-twilight-zone-1959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  84%|████████▍ | 42/50 [01:13<00:13,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/the-twilight-zone-1959\n",
      "✓ Found description for The Twilight Zone: An anthology series containing drama, psychological thriller, fantasy, science fiction, suspense, an...\n",
      "\n",
      "Scraping: Leyla and Mecnun (2011) - https://www.streamwithvpn.com/leyla-and-mecnun-2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  86%|████████▌ | 43/50 [01:15<00:11,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/leyla-and-mecnun-2011\n",
      "✓ Found description for Leyla and Mecnun: Leyla ile Mecnun is a Turkish television comedy series. The show is set in Istanbul, Turkey and prem...\n",
      "\n",
      "Scraping: Gravity Falls (2012) - https://www.streamwithvpn.com/gravity-falls-2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  88%|████████▊ | 44/50 [01:16<00:10,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/gravity-falls-2012\n",
      "✓ Found description for Gravity Falls: Twin brother and sister Dipper and Mabel Pines are in for an unexpected adventure when they spend th...\n",
      "\n",
      "Scraping: Cowboy Bebop (1998) - https://www.streamwithvpn.com/cowboy-bebop-1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  90%|█████████ | 45/50 [01:18<00:08,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/cowboy-bebop-1998\n",
      "✓ Found description for Cowboy Bebop: In 2071, roughly fifty years after an accident with a hyperspace gateway made the Earth almost uninh...\n",
      "\n",
      "Scraping: Fargo (2014) - https://www.streamwithvpn.com/fargo-2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  92%|█████████▏| 46/50 [01:20<00:06,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/fargo-2014\n",
      "✓ Found description for Fargo: A close-knit anthology series dealing with stories involving malice, violence and murder based in an...\n",
      "\n",
      "Scraping: Ted Lasso (2020) - https://www.streamwithvpn.com/ted-lasso-2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  94%|█████████▍| 47/50 [01:22<00:05,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/ted-lasso-2020\n",
      "✓ Found description for Ted Lasso: Ted Lasso, an American football coach, moves to England when he's hired to manage a soccer team—desp...\n",
      "\n",
      "Scraping: Kota Factory (2019) - https://www.streamwithvpn.com/kota-factory-2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  96%|█████████▌| 48/50 [01:23<00:03,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/kota-factory-2019\n",
      "✓ Found description for Kota Factory: In a city of coaching centers known to train India’s finest collegiate minds, an earnest but unexcep...\n",
      "\n",
      "Scraping: Succession (2018) - https://www.streamwithvpn.com/succession-2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies:  98%|█████████▊| 49/50 [01:25<00:01,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/succession-2018\n",
      "✓ Found description for Succession: Follow the lives of the Roy family as they contemplate their future once their aging father begins t...\n",
      "\n",
      "Scraping: Bluey (2018) - https://www.streamwithvpn.com/bluey-2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping movies: 100%|██████████| 50/50 [01:27<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Success with original URL: https://www.streamwithvpn.com/bluey-2018\n",
      "✓ Found description for Bluey: Bluey is an inexhaustible six year-old Blue Heeler dog, who loves to play and turns everyday family ...\n",
      "\n",
      "Scraping completed! Found data for 50 entries\n",
      "Success rate: 50 / 50\n",
      "\n",
      "Sample scraped data:\n",
      "                        title  \\\n",
      "0                Breaking Bad   \n",
      "1    The Shawshank Redemption   \n",
      "2  Avatar: The Last Airbender   \n",
      "3                    The Wire   \n",
      "4             Game of Thrones   \n",
      "\n",
      "                                                 url scrape_status  \\\n",
      "0    https://www.streamwithvpn.com/breaking-bad-2008       success   \n",
      "1  https://www.streamwithvpn.com/the-shawshank-re...       success   \n",
      "2  https://www.streamwithvpn.com/avatar-the-last-...       success   \n",
      "3        https://www.streamwithvpn.com/the-wire-2002       success   \n",
      "4  https://www.streamwithvpn.com/game-of-thrones-...       success   \n",
      "\n",
      "                                         description  cast  \n",
      "0  Walter White, a New Mexico chemistry teacher, ...  None  \n",
      "1  Imprisoned in the 1940s for the double murder ...  None  \n",
      "2  In a war-torn world of elemental magic, a youn...  None  \n",
      "3  Told from the points of view of both the Balti...  None  \n",
      "4  Seven noble families fight for control of the ...  None  \n",
      "\n",
      "Sample data saved to 'data/top10000_final.tsv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Web scraping script for StreamWithVPN data\n",
    "%pip install beautifulsoup4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "from urllib.parse import quote\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the top 10,000 weighted ratings data\n",
    "top_10000_df = pd.read_csv('data/top_10000_weighted_ratings.tsv', sep='\\t')\n",
    "\n",
    "def clean_title_for_url(title):\n",
    "    \"\"\"\n",
    "    Clean and format movie/series title for URL generation\n",
    "    \"\"\"\n",
    "    # Remove special characters and replace spaces with hyphens\n",
    "    cleaned = re.sub(r'[^\\w\\s-]', '', title)\n",
    "    cleaned = re.sub(r'\\s+', '-', cleaned.strip())\n",
    "    return cleaned.lower()\n",
    "\n",
    "def generate_streamwithvpn_url(title, year):\n",
    "    \"\"\"\n",
    "    Generate StreamWithVPN URL based on title and year\n",
    "    Example: \"The Wolf's Call\" (2019) -> \"https://www.streamwithvpn.com/the-wolfs-call-2019\"\n",
    "    \"\"\"\n",
    "    clean_title = clean_title_for_url(title)\n",
    "    # Handle cases where year might be NaN or missing\n",
    "    if pd.isna(year):\n",
    "        return f\"https://www.streamwithvpn.com/{clean_title}\"\n",
    "    else:\n",
    "        return f\"https://www.streamwithvpn.com/{clean_title}-{int(year)}\"\n",
    "\n",
    "def scrape_movie_data(url, tconst, title, year, endYear, titleType, isAdult, runtime, genres, rating, numVotes):\n",
    "    \"\"\"\n",
    "    Scrape movie/series data from StreamWithVPN\n",
    "    Returns dictionary with description, cast, and streaming platforms\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Add delay to be respectful to the server\n",
    "        time.sleep(1)\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        \n",
    "        # Try the original URL first\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            print(f\"✓ Success with original URL: {url}\")\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code in [404, 403]:  # Page not found or forbidden\n",
    "                # Try without year\n",
    "                url_without_year = generate_streamwithvpn_url(title, None)\n",
    "                print(f\"⚠ Original URL failed ({e.response.status_code}), trying without year: {url_without_year}\")\n",
    "                \n",
    "                try:\n",
    "                    response = requests.get(url_without_year, headers=headers, timeout=10)\n",
    "                    response.raise_for_status()\n",
    "                    print(f\"✓ Success with URL without year: {url_without_year}\")\n",
    "                    # Update the URL in the data dictionary for accuracy\n",
    "                    url = url_without_year\n",
    "                except requests.exceptions.HTTPError:\n",
    "                    print(f\"✗ Both URLs failed for {title}\")\n",
    "                    raise  # Re-raise the exception to be caught by outer try-catch\n",
    "            else:\n",
    "                raise  # Re-raise non-404/403 errors\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Initialize data dictionary\n",
    "        movie_data = {\n",
    "            'tconst': tconst,\n",
    "            'titleType': titleType,\n",
    "            'title': title,\n",
    "            'year': year,\n",
    "            'endYear': endYear,\n",
    "            'isAdult': isAdult,\n",
    "            'runtime': runtime,\n",
    "            'genres': genres,\n",
    "            'rating': rating,\n",
    "            'numVotes': numVotes,\n",
    "            'description': None,\n",
    "            'cast': None,\n",
    "            'streaming_platforms': None,\n",
    "            'url': url,\n",
    "            'scrape_status': 'success'\n",
    "        }\n",
    "        \n",
    "        # Extract DESCRIPTION - multiple approaches\n",
    "        description_element = soup.find('span', class_='rt-Text EntryDetailDescription_contentDescription__tXYGO EntryDetailDescription_expanded__3a0Gs')\n",
    "        \n",
    "        if not description_element:\n",
    "            description_element = soup.find('span', class_=re.compile('EntryDetailDescription_contentDescription'))\n",
    "        \n",
    "        if not description_element:\n",
    "            description_element = soup.find('span', class_=re.compile('contentDescription'))\n",
    "        \n",
    "        if not description_element:\n",
    "            description_element = soup.select_one('span[class*=\"EntryDetailDescription_contentDescription\"]')\n",
    "        \n",
    "        if description_element:\n",
    "            movie_data['description'] = description_element.get_text(strip=True)\n",
    "            #print(f\"✓ Found description for {title}: {movie_data['description'][:100]}...\")\n",
    "        else:\n",
    "            #print(f\"✗ No description found for {title}\")\n",
    "            pass\n",
    "        \n",
    "        \"\"\"\n",
    "        # Extract CAST information\n",
    "        cast_list = []\n",
    "        # Target container div\n",
    "        container_div = soup.find('div', class_='rt-Flex rt-r-fd-column rt-r-gap rt-r-px rt-r-pt rt-r-w', style='--gap: 2px; --pl: 16px; --pr: 16px; --pt: 8px; --width: 100%;')\n",
    "        if container_div:\n",
    "            cast_spans = container_div.find_all('span', {'data-accent-color': 'gray', 'class_': 'rt-Text rt-r-size-3 rt-r-weight-medium', 'style': 'min-width: 0px; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;'})\n",
    "            if cast_spans:\n",
    "                for span in cast_spans:\n",
    "                    cast_list.append(span.get_text(strip=True))\n",
    "                movie_data['cast'] = ', '.join(cast_list)\n",
    "                print(f\"✓ Found cast for {title}: {movie_data['cast'][:100]}...\")\n",
    "            else:\n",
    "                print(f\"✗ Span not found for {title}\")\n",
    "        else:\n",
    "            print(f\"✗ Div not found for {title}\")\n",
    "\n",
    "        # Extract STREAMING PLATFORMS information\n",
    "        platform_elements = soup.find_all('h2', class_='rt-Heading rt-r-size-5 rt-r-weight-medium rt-r-ta-left')\n",
    "        if platform_elements:\n",
    "            platforms = [elem.get_text(strip=True) for elem in platform_elements]\n",
    "            movie_data['streaming_platforms'] = ', '.join(platforms)\n",
    "        else:\n",
    "            print(f\"✗ No streaming platforms found for {title}\")\n",
    "        \"\"\"\n",
    "        \n",
    "        return movie_data\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request error for {title}: {e}\")\n",
    "        return {\n",
    "            'tconst': tconst,\n",
    "            'title': title,\n",
    "            'url': url,\n",
    "            'description': None,\n",
    "            'cast': None,\n",
    "            'streaming_platforms': None,\n",
    "            'scrape_status': f'request_error: {str(e)}'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Parsing error for {title}: {e}\")\n",
    "        return {\n",
    "            'tconst': tconst,\n",
    "            'title': title,\n",
    "            'url': url,\n",
    "            'description': None,\n",
    "            'cast': None,\n",
    "            'streaming_platforms': None,\n",
    "            'scrape_status': f'parsing_error: {str(e)}'\n",
    "        }\n",
    "\n",
    "# Initialize list to store scraped data\n",
    "scraped_data = []\n",
    "\n",
    "# Sample scraping for first 2 entries (for faster debugging)\n",
    "print(\"Starting web scraping\")\n",
    "sample_df = top_10000_df.head(50) # Change to 10000 for full run (2 for testing)\n",
    "\n",
    "for index, row in tqdm(sample_df.iterrows(), total=len(sample_df), desc=\"Scraping movies\"):\n",
    "    tconst = row['tconst']\n",
    "    title = row['primaryTitle']\n",
    "    year = row['startYear']\n",
    "    endYear = row['endYear']\n",
    "    titleType = row['titleType']\n",
    "    isAdult = row['isAdult']\n",
    "    runtime = row['runtimeMinutes']\n",
    "    genres = row['genres']\n",
    "    rating = row['averageRating']\n",
    "    numVotes = row['numVotes']\n",
    "    \n",
    "    \n",
    "    # Generate URL\n",
    "    url = generate_streamwithvpn_url(title, year)\n",
    "    print(f\"\\nScraping: {title} ({year}) - {url}\")\n",
    "    \n",
    "    # Scrape data\n",
    "    movie_data = scrape_movie_data(url, tconst, title, year, endYear, titleType, isAdult, runtime, genres, rating, numVotes)\n",
    "    scraped_data.append(movie_data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "scraped_df = pd.DataFrame(scraped_data)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nScraping completed! Found data for {len(scraped_df)} entries\")\n",
    "print(f\"Success rate: {len(scraped_df[scraped_df['scrape_status'] == 'success'])} / {len(scraped_df)}\")\n",
    "\n",
    "# Show sample results\n",
    "print(\"\\nSample scraped data:\")\n",
    "print(scraped_df[['title', 'url', 'scrape_status', 'description', 'cast']].head())\n",
    "\n",
    "# Save scraped data\n",
    "scraped_df.to_csv('data/top10000_final.tsv', sep='\\t', index=False)\n",
    "print(\"\\nSample data saved to 'data/top10000_final.tsv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvACFinal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
